{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG model\n",
    "vgg_model = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze current VGG16 model\n",
    "vgg_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meta', 'Meta.csv', 'Test', 'Test.csv', 'Train', 'Train.csv']\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\n"
     ]
    }
   ],
   "source": [
    "# Check datasets are found\n",
    "print(os.listdir('..\\\\data_raw'))\n",
    "cwd = os.getcwd() + \"\\\\..\\\\data_raw\\\\\"\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\0\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\1\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\2\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\3\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\4\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\5\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\6\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\7\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\8\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\9\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\10\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\11\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\12\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\13\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\14\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\15\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\16\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\17\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\18\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\19\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\20\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\21\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\22\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\23\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\24\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\25\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\26\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\27\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\28\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\29\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\30\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\31\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\32\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\33\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\34\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\35\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\36\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\37\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\38\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\39\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\40\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\41\n",
      "C:\\Users\\phill\\Dropbox\\College stuff\\Masters\\Year2\\COMP09012 - Machine Learning\\Assignment 2\\github\\assignment2\\..\\data_raw\\\\Train\\42\n",
      "(39209, 48, 48, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "# # Load Dataset\n",
    "height = 48\n",
    "width = 48\n",
    "channels = 3\n",
    "classes = 43\n",
    "n_inputs = height*width*channels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(classes):\n",
    "    path = cwd + \"\\\\Train\\\\\" + str(i)\n",
    "    print(path)\n",
    "    Class = os.listdir(path)\n",
    "    \n",
    "    for a in Class:\n",
    "        try:\n",
    "            image = cv2.imread(path + \"\\\\\" + a)\n",
    "            image_fromarray = Image.fromarray(image, 'RGB')\n",
    "            resize_image = image_fromarray.resize((height, width))\n",
    "            data.append(np.array(resize_image))\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error reading image.\")\n",
    "\n",
    "            \n",
    "#Create numpy arrays from input data            \n",
    "image_data = np.array(data)\n",
    "image_labels = np.array(labels)\n",
    "\n",
    "print(image_data.shape, image_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split up the data in train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_data, image_labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31367, 48, 48, 3)\n",
      "(7842, 48, 48, 3)\n",
      "(31367,)\n",
      "(7842,)\n",
      "(31367, 48, 48, 3)\n",
      "(7842, 48, 48, 3)\n",
      "(31367, 43)\n",
      "(7842, 43)\n"
     ]
    }
   ],
   "source": [
    "# Normalalize data\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 43)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 43)\n",
    "# x_train = x_train/255\n",
    "# x_test = x_test/255\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a classification Header\n",
    "end = vgg_model.layers[-1].output\n",
    "model = tf.keras.Model(vgg_model.input, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.trainable = True\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(43, activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramertise\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of Total batches: %d' % tf.data.experimental.cardinality(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup Test and validation testsets\n",
    "# total_batches = tf.data.experimental.cardinality(train_dataset)\n",
    "# test_dataset = train_dataset.take(total_batches // 10)\n",
    "# train_dataset = train_dataset.skip(total_batches // 10)\n",
    "# validation_dataset = train_dataset.take(total_batches // 5)\n",
    "# train_dataset = train_dataset.skip(total_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of train batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
    "# print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))\n",
    "# print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "y_train = tf.keras.utils.normalize(y_train, axis=1)\n",
    "y_test = tf.keras.utils.normalize(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configure Dataset for performance\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "# validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 2s 14ms/step - loss: 3.3467 - accuracy: 0.1190 - val_loss: 2.0062 - val_accuracy: 0.4436\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 2.0073 - accuracy: 0.4101 - val_loss: 1.2819 - val_accuracy: 0.6599\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 1.4775 - accuracy: 0.5395 - val_loss: 0.9774 - val_accuracy: 0.7429\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 1.2234 - accuracy: 0.6226 - val_loss: 0.8406 - val_accuracy: 0.7697\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 1.0784 - accuracy: 0.6623 - val_loss: 0.7205 - val_accuracy: 0.8015\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.9640 - accuracy: 0.6977 - val_loss: 0.6203 - val_accuracy: 0.8360\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.9217 - accuracy: 0.7109 - val_loss: 0.5476 - val_accuracy: 0.8595\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.8552 - accuracy: 0.7318 - val_loss: 0.5621 - val_accuracy: 0.8395\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.8138 - accuracy: 0.7438 - val_loss: 0.5046 - val_accuracy: 0.8706\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.7609 - accuracy: 0.7611 - val_loss: 0.4641 - val_accuracy: 0.8826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2f303e4c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=256,\n",
    "          validation_data=(x_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 851us/step - loss: 0.4641 - accuracy: 0.8826\n",
      "[0.46407458186149597, 0.8825554847717285]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               691300    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 709,775\n",
      "Trainable params: 709,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = train_dataset.class_names\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(class_names[labels[i]])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "# print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist = tf.keras.datasets.mnist\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Evaluation\n",
    "# val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "# print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot and show\n",
    "# plt.imshow(x_train[0])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
